@inproceedings{memo,
   author="Phillip Isola and Jianxiong Xiao and Antonio Torralba and Aude Oliva", 
   title="What makes an image memorable?", 
   booktitle="IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", 
   year="2011",
   pages="145-152"
}

@article{photo_mem,
  title={What makes a photograph memorable?},
  author={Isola, Phillip and Xiao, Jianxiong and Parikh, Devi and Torralba, Antonio and Oliva, Aude},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  volume={36},
  number={7},
  pages={1469--1482},
  year={2014},
  publisher={IEEE}
}

@inproceedings{image_mem_deep,
  title={Image memorability prediction using deep features},
  author={Zarezadeh, Soodabeh and Rezaeian, Mehdi and Sadeghi, Mohammad Taghi},
  booktitle={Electrical Engineering (ICEE), 2017 Iranian Conference on},
  pages={2176--2181},
  year={2017},
  organization={IEEE}
}

@inproceedings{mem_pred_bias,
  title={Deep learning for image memorability prediction: The emotional bias},
  author={Baveye, Yoann and Cohendet, Romain and Perreira Da Silva, Matthieu and Le Callet, Patrick},
  booktitle={Proceedings of the 2016 ACM on Multimedia Conference},
  pages={491--495},
  year={2016},
  organization={ACM}
}

@article{adap_transf,
  title={Predicting image memorability through adaptive transfer learning from external sources},
  author={Jing, Peiguang and Su, Yuting and Nie, Liqiang and Gu, Huimin},
  journal={IEEE Transactions on Multimedia},
  volume={19},
  number={5},
  pages={1050--1062},
  year={2017},
  publisher={IEEE}
}

@inproceedings{photo,
  title={Modifying the memorability of face photographs},
  author={Khosla, Aditya and Bainbridge, Wilma A and Torralba, Antonio and Oliva, Aude},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={3200--3207},
  year={2013}
}

@inproceedings{style,
  title={How to Make an Image More Memorable?: A Deep Style Transfer Approach},
  author={Siarohin, Aliaksandr and Zen, Gloria and Majtanovic, Cveta and Alameda-Pineda, Xavier and Ricci, Elisa and Sebe, Nicu},
  booktitle={Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval},
  pages={322--329},
  year={2017},
  organization={ACM}
}

@article{face,
  title={Changing the Image Memorability: From Basic Photo Editing to GANs},
  author={Sidorov, Oleksii},
  journal={arXiv preprint arXiv:1811.03825},
  year={2018}
}

@inproceedings{nvidia,
  title={High-resolution image synthesis and semantic manipulation with conditional gans},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8798--8807},
  year={2018}
}

@article{pix2pix,
  author    = {Phillip Isola and
               Jun{-}Yan Zhu and
               Tinghui Zhou and
               Alexei A. Efros},
  title     = {Image-to-Image Translation with Conditional Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1611.07004},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.07004},
  archivePrefix = {arXiv},
  eprint    = {1611.07004},
  timestamp = {Mon, 13 Aug 2018 16:49:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/IsolaZZE16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{city,
title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2016}
}

@inproceedings{lamem,
 author = {Khosla, Aditya and Raju, Akhil S. and Torralba, Antonio and Oliva, Aude},
 title = {Understanding and Predicting Image Memorability at a Large Scale},
 booktitle = {Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
 series = {ICCV '15},
 year = {2015},
 isbn = {978-1-4673-8391-2},
 pages = {2390--2398},
 numpages = {9},
 url = {http://dx.doi.org/10.1109/ICCV.2015.275},
 doi = {10.1109/ICCV.2015.275},
 acmid = {2919757},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

@inproceedings{amnet,
  title={AMNet: Memorability Estimation with Attention},
  author={Fajtl, Jiri and Argyriou, Vasileios and Monekosso, Dorothy and Remagnino, Paolo}
}
@inproceedings{celeb,
 author = {Ziwei Liu and Ping Luo and Xiaogang Wang and Xiaoou Tang},
 title = {Deep Learning Face Attributes in the Wild},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = December,
 year = {2015} 
}

@article{iso,
  title={The intrinsic memorability of face photographs.},
  author={Wilma A. Bainbridge and Phillip Isola and Aude Oliva},
  journal={Journal of experimental psychology. General},
  year={2013},
  volume={142 4},
  pages={
          1323-34
        }
}

@incollection{gene,
title = {Generative Adversarial Nets},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {2672--2680},
year = {2014},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf}
}

@article{cgan,
  title={Conditional Generative Adversarial Nets},
  author={Mehdi Mirza and Simon Osindero},
  journal={CoRR},
  year={2014},
  volume={abs/1411.1784}
}

@InProceedings{unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@inproceedings{attgan,
  title={AttGAN: Facial Attribute Editing by Only Changing What You Want},
  author={Zhenliang He and Wangmeng Zuo and Meina Kan and Shiguang Shan and Xilin Chen},
  year={2017}
}